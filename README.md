# RWKVInside

# HybridModel Overview

```mermaid
flowchart TB
    subgraph HybridModel
        input[Input] --> Embeddings
        Embeddings --> L0[Layer 0]
        
        subgraph Layer0[Layer 0]
            direction LR
            A0[AttentionWrapper] --> MLP0[MLP]
            subgraph AW0[AttentionWrapper 0]
                direction TB
                TA0[TeacherAttn\nFrozen] --> |Compare|SA0[StudentAttn\nRWKV TimeMixer]
                SA0 --> |Generate|VF0[v_first state 0]
            end
        end
        
        subgraph Layer1[Layer 1]
            direction LR
            A1[AttentionWrapper] --> MLP1[MLP]
            subgraph AW1[AttentionWrapper 1]
                direction TB
                TA1[TeacherAttn\nFrozen] --> |Compare|SA1[StudentAttn\nRWKV TimeMixer]
                SA1 --> |Generate|VF1[v_first state 1]
            end
        end
        
        subgraph LayerN[Layer N]
            direction LR
            AN[AttentionWrapper] --> MLPN[MLP]
            subgraph AWN[AttentionWrapper N]
                direction TB
                TAN[TeacherAttn\nFrozen] --> |Compare|SAN[StudentAttn\nRWKV TimeMixer]
                SAN --> |Generate|VFN[v_first state N]
            end
        end
        
        L0 --> L1[Layer 1]
        L1 --> LN[...]
        LN --> LayerN
        LayerN --> output[Output]
        
        subgraph VFirstHolder[VFirstHolder Distributed State]
            direction TB
            VS[Shared State\nShape: world_size x batch_size x seq_length x hidden_size]
        end
        
        %% v_first flow connections
        VF0 --> |Update Rank Slice|VS
        VS --> |Next Layer Input|VF1
        VF1 --> |Update Rank Slice|VS
        VS --> |Next Layer Input|VFN
        VFN --> |Update Rank Slice|VS
    end
    
    classDef default fill:#f9f9f9,stroke:#333,stroke-width:2px;
    classDef attention fill:#e1f5fe,stroke:#01579b,stroke-width:2px;
    classDef vfirst fill:#f3e5f5,stroke:#4a148c,stroke-width:2px;
    classDef mlp fill:#f1f8e9,stroke:#33691e,stroke-width:2px;
    
    class A0,A1,AN attention;
    class VF0,VF1,VFN,VS vfirst;
    class MLP0,MLP1,MLPN mlp;
```

## Training Process

```mermaid
graph TD
    A[å¼€å§‹] --> B[å‚æ•°åˆå§‹åŒ–]
    B --> C[åŠ è½½é…ç½®æ–‡ä»¶]
    C --> D[åˆå§‹åŒ–æ¨¡åž‹å’Œåˆ†è¯å™¨]
    D --> E[è®¾ç½®DeepSpeedé…ç½®]
    
    E --> F{åˆ¤æ–­è®­ç»ƒé˜¶æ®µ<br>stage 1/2/3}
    
    F -->|Stage 1| G1[åˆå§‹åŒ–æ•™å¸ˆæ³¨æ„åŠ›åˆ—è¡¨]
    F -->|Stage 2| G2[åˆå§‹åŒ–å®Œæ•´æ•™å¸ˆæ¨¡åž‹]
    F -->|Stage 3/SFT| G3[è·³è¿‡æ•™å¸ˆæ¨¡åž‹åˆå§‹åŒ–]
    
    G1 --> H[å‡†å¤‡æ•°æ®åŠ è½½å™¨]
    G2 --> H
    G3 --> H
    
    H --> I[å¼€å§‹è®­ç»ƒå¾ªçŽ¯]
    
    subgraph è®­ç»ƒå¾ªçŽ¯
        I --> J[æ›´æ–°å­¦ä¹ çŽ‡å’Œæƒé‡è¡°å‡]
        J --> K[å‰å‘ä¼ æ’­]
        K --> L[è®¡ç®—æŸå¤±]
        L --> M[åå‘ä¼ æ’­]
        M --> N{æ˜¯å¦ç´¯ç§¯æ­¥éª¤}
        N -->|æ˜¯| O[ä¼˜åŒ–å™¨æ­¥è¿›]
        N -->|å¦| P[ç»§ç»­ä¸‹ä¸€æ‰¹æ¬¡]
        O --> Q{æ£€æŸ¥ä¿å­˜æ¡ä»¶}
        P --> J
        Q -->|æ»¡è¶³| R[ä¿å­˜æ£€æŸ¥ç‚¹]
        Q -->|ä¸æ»¡è¶³| S{æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶}
        R --> S
        S -->|ç»§ç»­| J
        S -->|ç»ˆæ­¢| T[ç»“æŸè®­ç»ƒ]
    end
    
    subgraph æŸå¤±è®¡ç®—
        L --> L1[æ•™å¸ˆæŸå¤±]
        L --> L2[KLæ•£åº¦æŸå¤±]
        L --> L3[å­¦ç”Ÿäº¤å‰ç†µæŸå¤±]
    end
```
### Training shell

The training shell is the train.sh. Please  refer the train_memo.txt for more details for training in different stages.

## RL Training Process

```mermaid
flowchart TB
    subgraph Init["åˆå§‹åŒ–é˜¶æ®µ"]
        A[è§£æžå‘½ä»¤è¡Œå‚æ•°] --> B[è®¾ç½®åˆ†å¸ƒå¼çŽ¯å¢ƒ]
        B --> C[åŠ è½½åˆ†è¯å™¨]
        C --> D[åŠ è½½æ•°æ®é›†]
        D --> E[åˆ›å»ºDataLoader]
        E --> F[åˆå§‹åŒ–DeepSpeedé…ç½®]
    end

    subgraph Models["æ¨¡åž‹åˆå§‹åŒ–"]
        F --> G[åˆå§‹åŒ–ä¸»æ¨¡åž‹]
        G --> H[åˆå§‹åŒ–å‚è€ƒæ¨¡åž‹]
        H --> J[é…ç½®ä¼˜åŒ–å™¨]
    end

    subgraph Training["è®­ç»ƒå¾ªçŽ¯"]
        J --> K[è¿›å…¥è®­ç»ƒè½®æ¬¡]
        K --> L[æ‰¹æ¬¡è®­ç»ƒ]
        L --> M{æ˜¯å¦éœ€è¦ä¿å­˜æ£€æŸ¥ç‚¹}
        M -->|æ˜¯| N[ä¿å­˜æ¨¡åž‹æ£€æŸ¥ç‚¹]
        M -->|å¦| O[ç»§ç»­è®­ç»ƒ]
        N --> O
        O --> P{è½®æ¬¡ç»“æŸ?}
        P -->|å¦| L
        P -->|æ˜¯| Q[ä¿å­˜è½®æ¬¡æ£€æŸ¥ç‚¹]
        Q --> R{å…¨éƒ¨è½®æ¬¡å®Œæˆ?}
        R -->|å¦| K
        R -->|æ˜¯| S[è®­ç»ƒç»“æŸ]
    end

    subgraph TrainStep["æ‰¹æ¬¡è®­ç»ƒæ­¥éª¤(GRPOTrainer)"]
        L --> T[ç”Ÿæˆå®Œæˆå†…å®¹]
        T --> U[è®¡ç®—å¥–åŠ±]
        U --> V[è®¡ç®—KLæ•£åº¦]
        V --> W[å¤šæ¬¡æ›´æ–°è¿­ä»£]
        W --> X[è¿”å›žè®­ç»ƒæŒ‡æ ‡]
    end

    subgraph Metrics["æŒ‡æ ‡è®°å½•"]
        X --> Y[æ›´æ–°ç´¯è®¡ç»Ÿè®¡]
        Y --> Z[è®°å½•åˆ°WandB]
    end
```

### GRPO Algorithm from https://arxiv.org/pdf/2402.03300v3

![alt text](image-1.png)

The implementation of GRPO algorithm is rl/grpo_trainer.py , please refer the code for more details. TRL just eliminates the GRPO iteration and ignore the memory efficiency for large data in relative small machines. That's why we implement our own GRPO algorithm.
# Training ðŸ”¥

## Data preparation ðŸ¤—
- prepare input Raw data in [input_Raw_data_dir]
## Build Environment ðŸ¤¯
```bash
sudo apt install python3.12-venv
```
```bash
python -m venv .venv --system-site-packages
source .venv/bin/activate
pip install torch torchvision torchaudio gradio rwkv-fla accelerate deepspeed cupy
git clone https://github.com/uniartisan/transformers.git
cd ./transformers
pip install . 
```
## Train model ðŸ˜‹
- AMD complite Config '-xhip', '-fopenmp', '-ffast-math', '-O3', '--offload-arch=gfx1100','-munsafe-fp-atomics'
- Nvidia complite Config '-res-usage', '--maxrregcount 60', '--use_fast_math', '-O3', '-Xptxas -O3'
### Stage 1 
- Training for Qwen 0.5B with Norm

```bash
sh train.sh -c configs/qwen_0.5b.yaml -l 0.0001 -f 0.00001 -m 2048 -b 2 -r "[input_Raw_data_dir_1] [input_Raw_data_dir_2] [input_Raw_data_dir_3]..." -o [output_model_path]  -g 1 -F 0 -d 1 -t 1000_000_000 -T 0.2 -R v7 -s 1 -M 1
```
### Stage 2
- Training for Qwen 0.5B with Norm
```bash
sh train.sh -c configs/qwen_0.5b.yaml -l 0.0001 -f 0.00001 -m 2048 -b 2 -r "[input_Raw_data_dir_1] [input_Raw_data_dir_2] [input_Raw_data_dir_3]..." -o [Stage_1_output_model_dir]  -g 1 -F 0 -d 1 -t 1000_000_000 -T 0.2 -R v7 -s 2 -k [output_deepspeed_model_weight_dir] -M 1
```

- Training for Qwen 0.5B with Norm and freez mlp
```bash
sh train.sh -c configs/qwen_0.5b.yaml -l 0.0001 -f 0.00001 -m 2048 -b 2 -r "[input_Raw_data_dir_1] [input_Raw_data_dir_2] [input_Raw_data_dir_3]..." -o [Stage_1_output_model_dir]  -g 1 -F 0 -d 1 -t 1000_000_000 -T 0.2 -R v7 -s 2 -k [output_deepspeed_model_weight_dir] -M 1 -z 1
```

- Training for Qwen 0.5B with Norm and freez mlp and use another teacher model
```bash
sh train.sh -c configs/qwen_0.5b.yaml -l 0.0001 -f 0.00001 -m 2048 -b 2 -r "[input_Raw_data_dir_1] [input_Raw_data_dir_2] [input_Raw_data_dir_3]..." -o [Stage_1_output_model_dir]  -g 1 -F 0 -d 1 -t 1000_000_000 -T 0.2 -R v7 -s 2 -k [output_deepspeed_model_weight_dir] -M 1 -z 1 -i [Another_Instruct_teacher_model_dir_with_config]
```

[Jump to document describes the usage of the `train.sh` script for model training with DeepSpeed](./Train.md)

#### Because cupy only supports up to ROCm5.0, it cannot be trained on AMDGPU, but ROCM Pytorch can be used for infrence.

# Infrence on Nvidia GPU ðŸš€

## prepare model
1. convert deepspeed model to hf format 
```bash
python test/convert_2_hf.py --config_file [input_config_file] --ckpt_file [input_deepspeed_model_weight_dir] --output_config_dir [output_config_dir]
```

## Test model
1. test chat in cli
```bash
python ./test/test_chat_cli.py [model_config_dir]
```
2. test test caht in gradio with thinking
```bash
python ./test/test_hf_gradio_thinking.py [model_config_dir]
```
3. test chat in gradio with fp16
```bash
python ./test/test_hf_gradio.py [model_config_dir]
```
4. test by a single prompt with fp16
```bash
python ./test/test_hf.py [model_config_dir]
```

# Infrence on AMD Radeon GPU (Test on Ubuntu 24.04 with W7900 & RX6750xt)ðŸš€
1. [install ROCM Doc on Official Documentation](https://rocm.docs.amd.com/projects/install-on-linux/en/latest/install/install-methods/package-manager-index.html)
2. Build Environment
```bash
sudo apt install python3.12-venv
```
```bash
python -m venv .venv --system-site-packages
source .venv/bin/activate
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.2.4
pip install gradio rwkv-fla accelerate deepspeed cupy
git clone https://github.com/uniartisan/transformers.git
cd ./transformers
pip install . 
```
## prepare model
1. convert deepspeed model to hf format 
```bash
python test/convert_2_hf.py --config_file [input_config_file] --ckpt_file [input_deepspeed_model_weight_dir] --output_config_dir [output_config_dir]
```

## Test model
1. test chat in cli
```bash
python ./test/test_chat_cli.py [model_config_dir]
```
2. test test caht in gradio with thinking
```bash
python ./test/test_hf_gradio_thinking.py [model_config_dir]
```
3. test chat in gradio with fp16
```bash
python ./test/test_hf_gradio.py [model_config_dir]
```
4. test by a single prompt with fp16
```bash
python ./test/test_hf.py [model_config_dir]